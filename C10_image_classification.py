# -*- coding: utf-8 -*-
"""10 Image classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VOSVg3f7zRVrvT4BLAeKpX1Zw-y3xXWc

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras import Sequential
from tensorflow.keras.layers import InputLayer, Conv2D, MaxPool2D, Dense, Flatten
"""

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
import numpy as np
# Parameters
input_shape = (28,56,1)  # Image dimensions (Height, Width, Channels)
batch_size = 32
epochs = 10
def show_img(x, y):
    plt.gray()
    plt.title(str(y))
    plt.imshow(x)
# Paths to dataset
dataset=np.load('/content/drive/MyDrive/CVExamDatasets /Image_classification/mnist_compressed.npz')
x_train =dataset['train_images']
x_test=dataset['test_images']
y_train=dataset['train_labels']
y_test=dataset['test_labels']
print(x_train.shape)
test_full_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))
train = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10)
DATASET_SIZE = len(train)
train_dataset = train.take(int(0.8 * DATASET_SIZE)).map(lambda x, y:
        (
            tf.reshape(x , (28 , 56 , 1))
            , y
        )
    ).batch(32)

val_dataset = train.skip(int(0.8 * DATASET_SIZE)).map(lambda x, y:
        (
            tf.reshape(x , (28 , 56 , 1))
            , y
        )
    ).batch(32)
model = Sequential([
    Conv2D(filters = 8, kernel_size = (3 , 3), strides = 1, padding = 'same', activation = 'relu', input_shape = (28, 56, 1)),
    MaxPooling2D(pool_size = (2 , 2), strides = 2),

    Conv2D(filters = 16, kernel_size = (3 , 3), strides = 1, padding = 'same', activation = 'relu'),
    MaxPooling2D(pool_size = (2 , 2), strides = 2),

    Flatten(),
    Dense(100, activation = 'softmax')
])
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
model.fit(train_dataset, validation_data = val_dataset, epochs=20)
x = x_test[69]
y = y_test[69]
x = x_test[69]
y = y_test[69]
show_img(x , y)
x = x.reshape(1, 28, 56, 1)
predictions = model.predict(x, verbose=0)
# Get predicted class and confidence
predicted_class = np.argmax(predictions[0])
confidence = predictions[0][predicted_class]
print('class =', predicted_class, 'conf=' , confidence)

###NEW


from tensorflow import keras
import matplotlib.pyplot as plt
import numpy as np

# Load MNIST dataset from file
def load_mnist_data(file_path):
    with np.load(file_path) as dataset:
        X_train = dataset["train_images"]
        y_train = dataset["train_labels"]
        X_test = dataset["test_images"]
        y_test = dataset["test_labels"]
    return X_train, y_train, X_test, y_test

# Normalize the data
def normalize_data(X_train, X_test):
    X_train = X_train / 255.0
    X_test = X_test / 255.0
    return X_train, X_test

# Create ANN model
# def create_ann_model():
#     ann = keras.models.Sequential([
#         keras.layers.Flatten(input_shape=(28, 56)),
#         keras.layers.Dense(3000, activation='relu'),
#         keras.layers.Dense(1000, activation='relu'),
#         keras.layers.Dense(100, activation='softmax')
#     ])
#     ann.compile(optimizer='SGD',
#                 loss='sparse_categorical_crossentropy',
#                 metrics=['accuracy'])
#     return ann

# Create CNN model
def create_cnn_model():
    cnn = keras.models.Sequential([
        keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(28, 56, 1)),
        keras.layers.MaxPooling2D((2, 2)),
        keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),
        keras.layers.MaxPooling2D((2, 2)),
        keras.layers.Flatten(),
        keras.layers.Dense(64, activation='relu'),
        keras.layers.Dense(100, activation='softmax')
    ])
    cnn.compile(optimizer='adam',
                loss='sparse_categorical_crossentropy',
                metrics=['accuracy'])
    return cnn

# Plot a sample
def plot_sample(X, y, index):
    plt.figure(figsize=(5, 5))
    plt.imshow(X[index].squeeze(), cmap='gray')
    plt.xlabel(f"Label: {y[index]}")

# Evaluate model
def evaluate_model(model, X_test, y_test):
    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)
    print('Test accuracy:', test_acc)

# Load and preprocess the dataset
file_path = "C:\\Codes\\Assignments\\CVDL\\datasets\\CVDLDataset\\mnist_compressed.npz"

# Debug dataset shapes
X_train, y_train, X_test, y_test = load_mnist_data(file_path)
print(f"X_train shape: {X_train.shape}")
print(f"y_train shape: {y_train.shape}")
print(f"X_test shape: {X_test.shape}")
print(f"y_test shape: {y_test.shape}")

# Ensure cardinality matches
if len(X_train) != len(y_train):
    X_train = X_train[:len(y_train)]

# Normalize data
X_train, X_test = normalize_data(X_train, X_test)

# Reshape for CNN
X_train_cnn = X_train.reshape(-1, 28, 56, 1)
X_test_cnn = X_test.reshape(-1, 28, 56, 1)

# # Prepare data for ANN
# X_train_ann = X_train.reshape(-1, 28, 56)
# X_test_ann = X_test.reshape(-1, 28, 56)

# print(f"ANN-ready X_train shape: {X_train_ann.shape}")
print(f"CNN-ready X_train shape: {X_train_cnn.shape}")

# # Train ANN model
# print("\nTraining ANN Model:")
# ann = create_ann_model()
# ann.fit(X_train_ann, y_train, epochs=5)
# evaluate_model(ann, X_test_ann, y_test)

# Train CNN model
print("\nTraining CNN Model:")
cnn = create_cnn_model()
cnn.fit(X_train_cnn, y_train, epochs=5)
evaluate_model(cnn, X_test_cnn, y_test)

# Plot a sample image
# plot_sample(X_test_ann, y_test, 0)
plt.show()
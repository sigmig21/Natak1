# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10AFI9l8Wfl36XeTDlYpjPv19d4CkLool
"""

# Import necessary libraries
from unet import unet_model
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from sklearn.model_selection import train_test_split
import os
import numpy as np
import matplotlib.pyplot as plt

# Define paths for image and label folders
image_folder = r"/content/drive/MyDrive/CVExamDatasets /semantic segmentation/Images"
label_folder = r"/content/drive/MyDrive/CVExamDatasets /semantic segmentation/Labels"

# Define the target size for resizing images
img_size = (128, 128)

# Initialize lists to hold images and their corresponding labels
images = []
labels = []

# Load and preprocess the input images
for img_name in os.listdir(image_folder):
    image_path = os.path.join(image_folder, img_name)  # Get full image path
    image = load_img(image_path, target_size=img_size)  # Load and resize image
    images.append(img_to_array(image) / 255.0)  # Normalize pixel values to [0, 1]

# Load and preprocess the labels
for label_name in os.listdir(label_folder):
    label_path = os.path.join(label_folder, label_name)  # Get full label path
    label = load_img(label_path, target_size=img_size, color_mode="grayscale")  # Load and resize label
    labels.append(img_to_array(label) / 255.0)  # Normalize pixel values to [0, 1]

# Expand dimensions of labels to match input shape
labels = np.expand_dims(labels, axis=-1)

# Split the dataset into training and validation sets
x_train, x_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42)

# Ensure training and label data have matching lengths
x_train, y_train = x_train[:min(len(x_train), len(y_train))], y_train[:min(len(x_train), len(y_train))]

# Build the U-Net model using the unet library
model = unet_model(
    input_size=(128, 128, 3),  # Input shape for the images
    num_classes=1,            # Single class for binary segmentation
    activation="sigmoid"      # Output activation
)

# Compile the model
model.compile(optimizer="adam", loss="binary_crossentropy", metrics=['accuracy'])

# Train the model
history = model.fit(
    np.array(x_train), np.array(y_train),
    validation_data=(np.array(x_val), np.array(y_val)),
    epochs=10,
    batch_size=30
)

# Visualize a sample prediction (optional)
sample_img = x_val[5]
sample_label = y_val[5]
predicted_mask = model.predict(np.expand_dims(sample_img, axis=0))[0]

plt.figure(figsize=(10, 5))
plt.subplot(1, 3, 1)
plt.title("Input Image")
plt.imshow(sample_img)

plt.subplot(1, 3, 2)
plt.title("True Mask")
plt.imshow(sample_label.squeeze(), cmap='gray')

plt.subplot(1, 3, 3)
plt.title("Predicted Mask")
plt.imshow(predicted_mask.squeeze(), cmap='gray')
plt.show()